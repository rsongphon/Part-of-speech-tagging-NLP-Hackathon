{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ONNX_Inference_Model_show.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoS3mSrBsnt4"
      },
      "outputs": [],
      "source": [
        "!pip install numpy protobuf==3.16.0\n",
        "!pip install onnx\n",
        "!pip install -q simpletransformers\n",
        "!pip install -q datasets transformers[sentencepiece] simpletransformers\n",
        "!pip install onnxruntime\n",
        "!pip install transformers[onnx]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RUdK03YCTI7",
        "outputId": "c6e83de1-b439-4db7-e1fa-c38bc1d8c8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "to_predict = ['ไ่ก่ จิก เด็ก ตาย คน _ เกิด บน ปาก โอ่ง']"
      ],
      "metadata": {
        "id": "04_ZHJ9azMCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_POS_TAGS = [\"NN\", \"VV\", \"PU\", \"CC\", \"PS\", \"AX\", \"AV\", \"FX\", \"NU\", \"AJ\", \"CL\", \"PR\", \"NG\", \"PA\", \"XX\", \"IJ\"]"
      ],
      "metadata": {
        "id": "-K-g_Z7UzPdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.camembert import CamembertTokenizer\n",
        "from onnxruntime import InferenceSession, SessionOptions\n",
        "import os\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "szCZ3E9ouHfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = True\n",
        "cuda_device=-1"
      ],
      "metadata": {
        "id": "TrSWKdNgqUik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Cuda on local machine\n",
        "# No need for cuda if use in inference server\n",
        "if use_cuda:\n",
        "    if torch.cuda.is_available():\n",
        "        if cuda_device == -1:\n",
        "            device = torch.device(\"cuda\")\n",
        "        else:\n",
        "            device = torch.device(f\"cuda:{cuda_device}\")\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"'use_cuda' set to True when cuda is unavailable.\"\n",
        "            \"Make sure CUDA is available or set use_cuda=False.\"\n",
        "        )\n",
        "else:\n",
        "    device = \"cpu\""
      ],
      "metadata": {
        "id": "v-0DTKsSqTLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare Onnx runtime\n",
        "\n",
        "onnx_execution_provider = ([\"CUDAExecutionProvider\"] if use_cuda else [\"CPUExecutionProvider\"])\n",
        "\n",
        "options = SessionOptions()\n",
        "\n",
        "model_path = '/content/drive/MyDrive/POSTAG/BERT_model/ONNXModel(Noquantize)/onnx_model.onnx' ### ไฟล์.onnx โมเดล ONNX ที่เรา train\n",
        "model = InferenceSession(model_path, options, providers=onnx_execution_provider)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB9gArtApKiQ",
        "outputId": "cf5fda0b-56fa-4750-8bd4-3eaa493352c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:56: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
            "  \"Available providers: '{}'\".format(name, \", \".join(available_provider_names)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ประกาศ tokenizer\n",
        "tokenizer_class = CamembertTokenizer\n",
        "\n",
        "\n",
        "model_name = '/content/drive/MyDrive/POSTAG/BERT_model/ONNXModel(Noquantize)'  # โฟลเดอร์ที่เก็บโมเดลและ argument (เอาทั้งโฟลเดอร์)\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(model_name, do_lower_case=False,)"
      ],
      "metadata": {
        "id": "6WlzmYZktLLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode Input\n",
        "model_inputs = tokenizer.batch_encode_plus(\n",
        "                to_predict,\n",
        "                return_tensors=\"np\", #pt\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                is_split_into_words=(False),\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPDeWP8vzp1I",
        "outputId": "1ed62ad8-d53c-48c1-ea9d-80673a37a4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSZEqnyCzp3e",
        "outputId": "2f242677-f816-44b0-ac36-f9b8b995bba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': array([[    5,    10,  2840,   369,  7711,    10,  6803,  6345,    10,\n",
              "          288,  2246,    10,   265,    10,   301,    10,   326,    10,\n",
              "          573,    10, 22751,     6]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get input\n",
        "input_ids = model_inputs[\"input_ids\"]\n",
        "attention_mask = model_inputs[\"attention_mask\"]"
      ],
      "metadata": {
        "id": "IMVy5lf9zp5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Prediction 1 sentence ######\n",
        "inputs_onnx = { \"input_ids\": input_ids,\n",
        "                \"attention_mask\": attention_mask,}\n",
        "\n",
        "output = model.run(None, inputs_onnx)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "LwDtFZ9bEan_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get correct output shape\n",
        "output = np.array(output)\n",
        "output = output[0].copy()\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHUVZr-JE2Vh",
        "outputId": "24991577-2936-4f92-9dda-1a758f8f5352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 22, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction \n",
        "preds = np.argmax(output, axis=2)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcvLhYFDI05e",
        "outputId": "c7846975-9364-4573-b68e-8862135999e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  0,  0,  1,  1,  1,  1,  0,  1,  1, 10,  2,  2,  1,  1,  4,\n",
              "         0,  0,  0,  0,  0,  3]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix bug in simpletransformers\n",
        "\n",
        "out_input_ids = inputs_onnx[\"input_ids\"]\n",
        "out_attention_mask = inputs_onnx[\"attention_mask\"]\n",
        "\n",
        "pad_token_label_id = -100\n",
        "out_label_ids = [[] for _ in range(len(to_predict))]\n",
        "max_len = len(out_input_ids[0])\n",
        "\n",
        "for index, sentence in enumerate(to_predict):\n",
        "    for word in sentence.split():\n",
        "        word_tokens = tokenizer.tokenize(word)\n",
        "        out_label_ids[index].extend(\n",
        "        [0] + [pad_token_label_id] * (len(word_tokens) - 1)\n",
        "    )\n",
        "    out_label_ids[index].insert(0,pad_token_label_id)\n",
        "    out_label_ids[index].append(pad_token_label_id)\n",
        "\n",
        "    if len(out_label_ids[index]) < max_len:\n",
        "        out_label_ids[index].extend([-100] * (max_len-len(out_label_ids[index])))\n",
        "\n",
        "out_label_ids = np.array(out_label_ids).reshape(len(out_label_ids), max_len)"
      ],
      "metadata": {
        "id": "Em3QM3L9zqC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map label\n",
        "label_map = {i: label for i, label in enumerate(_POS_TAGS)}"
      ],
      "metadata": {
        "id": "eMvwiH7tzqKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map"
      ],
      "metadata": {
        "id": "g9PMLSHuFdsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f769263-6bad-4f37-ead7-0244dd3d4c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NN',\n",
              " 1: 'VV',\n",
              " 2: 'PU',\n",
              " 3: 'CC',\n",
              " 4: 'PS',\n",
              " 5: 'AX',\n",
              " 6: 'AV',\n",
              " 7: 'FX',\n",
              " 8: 'NU',\n",
              " 9: 'AJ',\n",
              " 10: 'CL',\n",
              " 11: 'PR',\n",
              " 12: 'NG',\n",
              " 13: 'PA',\n",
              " 14: 'XX',\n",
              " 15: 'IJ'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# map word แต่ละคำ กับ POS/NER ในรูปแแบบ dict\n",
        "out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "for i in range(out_label_ids.shape[0]):\n",
        "    for j in range(out_label_ids.shape[1]):\n",
        "        if out_label_ids[i, j] != pad_token_label_id:\n",
        "            out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
        "            preds_list[i].append(label_map[preds[i][j]])\n",
        "\n",
        "preds = [\n",
        "            [\n",
        "              {word: preds_list[i][j]}\n",
        "              for j, word in enumerate(sentence.split()[: len(preds_list[i])])\n",
        "            ]\n",
        "              for i, sentence in enumerate(to_predict)\n",
        "        ]"
      ],
      "metadata": {
        "id": "SX5kwDqozqMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rQ7c-L6zqWG",
        "outputId": "3fcfc1c9-aa6e-484d-c191-b9254297d275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'ไ่ก่': 'NN'},\n",
              "  {'จิก': 'VV'},\n",
              "  {'เด็ก': 'NN'},\n",
              "  {'ตาย': 'VV'},\n",
              "  {'คน': 'CL'},\n",
              "  {'_': 'PU'},\n",
              "  {'เกิด': 'VV'},\n",
              "  {'บน': 'PS'},\n",
              "  {'ปาก': 'NN'},\n",
              "  {'โอ่ง': 'NN'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}